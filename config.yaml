# TODO: add papers by configuration file
base_url: "https://arxiv.paperswithcode.com/api/v0/papers/"
user_name: "zzh"
repo_name: "nlp-arxiv-daily"
show_authors: True
show_links: True
show_badge: True
max_results: 20

publish_readme: True
publish_gitpage: True
publish_wechat: False

# file paths
json_readme_path: "./docs/nlp-arxiv-daily.json"
json_gitpage_path: "./docs/nlp-arxiv-daily-web.json"

md_readme_path: "README.md"
md_gitpage_path: "./docs/index.md"

# keywords to search
keywords:
  "LLM":
    filters: [ "LLM", "Large Language Model","text generation" ]
  "retrieval arguments":
    filters: [ "retrieval argument*", "retrieval enhance*","vector search" ]
  "Code Generation":
    filters: ["Code Generation"]


#    "NLP":
#      filters: [ "NLP", "Natural Language Processing" ]
#    "Legal NLP":
#      filters: [ "Legal NLP", "Legal Language", "Legal Text" ]
#    "Sequence Annotation":
#      filters: [ "Sequence Annotation", "Sequence Marking" ]
#    "Named Entity Recognition":
#      filters: [ "Named Entity Recognition" ]
#    "Text Classification":
#      filters:
#        [
#          "Text Classification",
#          "Topic Labeling",
#          "News Classification",
#          "Dialog Act Classification",
#          "Natural Language Inference",
#          "Relation Classification",
#          "Event Prediction",
#        ]
#    "Sentiment Analysis":
#      filters: [ "Sentiment Analysis" ]
#    "Question Answering":
#      filters: [ "QA", "Question Answering" ]
#    "Information Extraction":
#      filters:
#        [
#          "Information Extraction",
#          "Automatic Summary",
#          "Title Generation",
#          "Event Extraction",
#        ]
#    "Recommendation System":
#      filters: [ "Recommendation System", "Semantic Matching", "Chatbots" ]
#    "Knowledge Graph":
#      filters: [ "Knowledge Graph", "Knowledge Graphs" ]
